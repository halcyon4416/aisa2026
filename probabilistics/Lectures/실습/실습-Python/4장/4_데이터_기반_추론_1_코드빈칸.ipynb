{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# LGE - SNU AI Scientist 고급과정 [확률통계 및 통계 방법론]\n",
        "## 4장: 데이터 기반 추론 1\n",
        "### TA: 홍현경(hyungyeong81@snu.ac.kr)"
      ],
      "metadata": {
        "id": "Wd2kouZxWRhl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. 구간추정\n",
        "\n",
        "- 신뢰수준 (Confidence level)이 $100(1-\\alpha)\\%$인 신뢰구간 $(L, U)$는 다음을 만족한다.\n",
        "\n",
        "$$\n",
        "P(L \\le \\theta \\le U) = 1 - \\alpha\n",
        "$$\n",
        "\n",
        "\n",
        "- 모분산 $\\sigma^2$를 알 때 정규모집단의 모평균 $\\mu$의 신뢰수준 $100(1-\\alpha)\\%$인 신뢰구간은 다음과 같다.\n",
        "\n",
        "$$\n",
        "\\left(\n",
        "\\bar{X} - z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}},\n",
        "\\;\n",
        "\\bar{X} + z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\n",
        "\\right)\n",
        "$$\n"
      ],
      "metadata": {
        "id": "fHP1rjvDWcO5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(구간추정 실습)\n",
        "\n",
        "이 실습에서는 정규분포를 따르는 모집단에서 반복 표본추출을 수행하고, 각 표본으로부터 계산한 95% 신뢰구간이 모평균 $\\mu$를 포함하는지 여부를 시각적으로 확인한다. 이를 통해 신뢰구간의 95% 라는 의미를 직관적으로 이해한다.\n",
        "\n",
        "- 평균 $\\mu = 50$, 표준편차 $\\sigma = 10$인 정규분포를 따르는 모집단을 가정한다.\n",
        "- 표본 크기는 $n = 25$로 고정한다.\n",
        "- 서로 독립적인 표본추출을 20번 반복하여 각 표본의 표본평균을 계산한다. 이 때, 정규모집단을 가정하므로, 각 반복에서 표본을 직접 생성해 평균을 계산하는 대신, 표본평균이 따르는 분포 $N(\\mu,\\sigma^2/n)$에서 표본평균을 직접 생성하는 방법을 고려할 수 있다.\n",
        "- 모표준편차 $\\sigma$가 알려져 있으므로, 정규분포 기반의 신뢰구간\n",
        "  $$\n",
        "  \\bar{X} \\pm z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\n",
        "  $$\n",
        "  을 사용하여 각 표본에 대한 95% 신뢰구간을 계산한다.\n",
        "- 각 신뢰구간이 실제 모평균 $\\mu$를 포함하는지 여부를 확인한다.\n",
        "- 신뢰구간을 수평선으로 시각화하되,\n",
        "  - $\\mu$를 포함하는 경우는 노란색 실선\n",
        "  - 포함하지 않는 경우는 빨간색 점선\n",
        "  으로 구분한다.\n",
        "- 각 표본평균은 점으로 표시하고, 실제 모평균 $\\mu$는 수직선으로 나타낸다."
      ],
      "metadata": {
        "id": "1aXjYdC4YCRt"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QJ8Jd-hAGeDi"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(81)\n",
        "mu = 50\n",
        "sigma = 10\n",
        "n = 25\n",
        "alpha = 0.05\n",
        "z = 1.96 # 또는 norm.ppf(1 - alpha / 2, loc = 0, scale = 1)\n",
        "num_samples = 20\n",
        "\n",
        "\n",
        "# 표본평균 생성\n",
        "\n",
        "# ------------------\n",
        "# 코드 채우기\n",
        "# ------------------\n",
        "\n",
        "\n",
        "# 신뢰구간 계산\n",
        "\n",
        "# ------------------\n",
        "# 코드 채우기\n",
        "# ------------------\n",
        "\n",
        "\n",
        "# 시각화\n",
        "fig, ax = plt.subplots(figsize=(8, 5))\n",
        "\n",
        "y_positions = np.arange(num_samples)[::-1]\n",
        "\n",
        "ax.hlines(y_positions[contains], lower[contains], upper[contains], color='skyblue', linewidth=3)\n",
        "ax.hlines(y_positions[~contains], lower[~contains], upper[~contains], color='blue', linewidth=3, linestyles='--')\n",
        "\n",
        "ax.scatter(xbar[contains], y_positions[contains], color='skyblue', edgecolors='black', s=80, zorder=3)\n",
        "ax.scatter(xbar[~contains], y_positions[~contains], color='blue', s=80, marker='x', zorder=3)\n",
        "\n",
        "ax.axvline(mu, color='black', linewidth=2)\n",
        "\n",
        "ax.set_yticks([])\n",
        "ax.set_xticks([])\n",
        "ax.set_xlabel('')\n",
        "ax.set_ylabel('')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "따라서, 100번의 표본 추출을 통해 얻어진 100개의 신뢰구간  \n",
        "$$\\left(\n",
        "\\bar{X} - z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}},\n",
        "\\;\n",
        "\\bar{X} + z_{1-\\alpha/2}\\frac{\\sigma}{\\sqrt{n}}\n",
        "\\right)$$ 에서, $100(1-\\alpha)\\%$ 개 정도의 신뢰구간이 모평균 $\\mu$를 포함한다고 해석할 수 있다."
      ],
      "metadata": {
        "id": "Ztdy6OM2bXNO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. 부트스트래핑(Bootstrapping)"
      ],
      "metadata": {
        "id": "wa1cJ59pd5t7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "(부트스트래핑 예제 1)\n",
        "\n",
        "- 본 실습은 강의에서 다룬 표본분포 개념을 실제 MLB 투구 데이터에 적용하여 확인하는 것을 목표로 한다. 특히, 스트라이크존 경계 근처에 위치한 판정이 애매한 투구들에 대하여, 하나의 표본으로부터 계산된 표본비율이 얼마나 변동할 수 있는지를 부트스트래핑을 통해 살펴본다.\n",
        "\n",
        "- 본 실습의 궁극적인 관심 대상은 스트라이크존 경계 투구에 대해 심판의 판정이 ABS 판정과 일치할 확률\n",
        "$$\n",
        "\\theta = P(\\text{심판 판정이 ABS와 일치})\n",
        "$$\n",
        "이다. 이를 추정하기 위해, 2024년 4월 1일부터 4월 7일까지의 MLB 경기에서 관측된 스트라이크존 경계 근처 투구들을 하나의 표본으로 사용한다. 이 기간 동안 관측된 판정이 애매한 투구의 총 개수를 $N$이라 하자.\n",
        "\n",
        "- 각 투구에 대해 ABS 판정을 기준으로 사람 심판의 판정이 일치하면 정답(1), 불일치하면 오답(0)으로 기록하며, 이를 $X_1, X_2, \\dots, X_N$으로 나타낸다. 이때 각 $X_i$는 확률 $\\theta$를 갖는 베르누이 확률변수의 관측치로 해석할 수 있다.\n",
        "\n",
        "- 표본으로부터 계산되는 표본비율\n",
        "$$\n",
        "{\\hat \\theta} = \\frac{1}{N}\\sum_{i=1}^N X_i\n",
        "$$\n",
        "은 심판 판정 정확도 $\\theta$의 추정량이다. 그러나 실제로 동일한 조건에서 새로운 투구를 반복 관측하는 것은 불가능하므로, 본 실습에서는 관측된 데이터 $\\{X_1,\\dots,X_N\\}$를 기반으로 추정량의 변동성을 살펴보기 위해 부트스트랩 방법을 사용한다.\n",
        "\n",
        "- 구체적으로, 관측된 데이터로부터 동일한 크기($n$)의 표본을 $B = 2000$번 복원추출하여 부트스트랩 표본을 반복적으로 생성하고, 각 부트스트랩 표본에 대해 표본비율\n",
        "$$\n",
        "\\hat{\\theta}^* = \\frac{1}{n}\\sum_{i=1}^{n} X_i^*\n",
        "$$\n",
        "을 계산한다. 이러한 과정을 여러 번 반복하여 얻어진 $\\hat{\\theta}^*$들의 분포를 표본비율 추정량의 부트스트랩 분포라고 한다.\n",
        "\n",
        "- 이제 우리는 부트스트랩 표본들로부터 계산된 표본비율들의 분포를 히스토그램으로 시각화함으로써, 표본비율 추정량이 가지는 변동성과 분포의 형태를 데이터 기반으로 직관적으로 이해하고자 한다."
      ],
      "metadata": {
        "id": "Vt-D9o0jd50V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**(참고: 배경지식)**\n",
        "- ABS 판정은 다음 규칙을 따른다.\n",
        "\n",
        "  - 공의 중심 좌표는 $(plate\\_x, plate\\_z)$이다.\n",
        "  - 타자별 스트라이크존 상단과 하단은 $sz\\_top$, $sz\\_bot$이다.\n",
        "  - 공의 일부라도 스트라이크존과 겹치면 스트라이크로 판정한다.\n",
        "\n",
        "- 수평 방향 조건은 다음과 같다.\n",
        "\n",
        "$$\n",
        "|plate\\_x| \\le \\frac{17/2}{12} + \\frac{1.43}{12}\n",
        "$$\n",
        "\n",
        "- 수직 방향 조건은 다음과 같다.\n",
        "\n",
        "$$\n",
        "sz\\_bot - \\frac{1.43}{12}\n",
        "\\le plate\\_z \\le\n",
        "sz\\_top + \\frac{1.43}{12}.\n",
        "$$\n",
        "\n",
        "- 본 실습에서는 판정이 가장 어려운 상황에 집중하기 위해, 스트라이크존 경계 근처의 투구만 사용한다. 경계 투구는 다음 조건 중 하나라도 만족하면 포함한다.\n",
        "\n",
        "$$\n",
        "|dx| \\le margin\n",
        "\\quad \\text{또는} \\quad\n",
        "|dz_{low}| \\le margin\n",
        "\\quad \\text{또는} \\quad\n",
        "|dz_{high}| \\le margin\n",
        "$$\n",
        "\n",
        "- 여기서 $dx, dz_{low}, dz_{high}$는 각각 좌우/하단/상단 경계까지의 거리이다. 실습에서는 $margin= 0.1$피트 (약 1.2인치)를 사용한다.\n",
        "\n",
        "- 한편, MLB ABS 공식 규정에서는 스트라이크존의 상단과 하단을 타자 키의 비율(상단 53.5%, 하단 27%)로 정의한다.  \n",
        "그러나 본 실습에서는 해당 비율을 직접 적용하는 대신, Statcast에서 제공하는 타자별 스트라이크존 변수 $sz\\_top$, $sz\\_bot$을 사용하여 ABS 스트라이크존을 근사한다. 이는 실제 경기 데이터에 기반한 현실적인 판정 기준을 적용하기 위함이다.\n",
        "\n",
        "- 따라서 본 실습에서의 ABS 판정은 MLB ABS 규정을 엄밀히 재현한 것은 아니며 Statcast 기반 스트라이크존을 이용한 실무적인 근사로 이해한다."
      ],
      "metadata": {
        "id": "O8Mi2ny0cn7I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from pybaseball import statcast\n",
        "\n",
        "# -----------------------------\n",
        "# 1) Statcast 데이터 불러오기\n",
        "# -----------------------------\n",
        "START_DATE = \"2024-04-01\" # 검색 시작일\n",
        "END_DATE   = \"2024-04-07\" # 검색 종료일\n",
        "\n",
        "df = statcast(start_dt=START_DATE, end_dt=END_DATE) # 데이터 호출\n",
        "\n",
        "# -----------------------------\n",
        "# 2) 심판의 판정이 존재하는 투구만 선택 (called_strike, ball만 사용 / 스윙, 파울, 사구 등은 제외)\n",
        "# -----------------------------\n",
        "df = df[df[\"description\"].isin([\"called_strike\", \"ball\"])].copy()\n",
        "\n",
        "# 스트라이크존 판정에 필요한 변수 결측치 제거\n",
        "df = df.dropna(subset=[\"plate_x\", \"plate_z\", \"sz_top\", \"sz_bot\"]).copy()\n",
        "\n",
        "# -----------------------------\n",
        "# 3) 스트라이크존 정의\n",
        "#    - 공의 일부라도 스트라이크존과 겹치면 스트라이크로 판정\n",
        "#    - plate_x, plate_z는 공의 중심 좌표\n",
        "#    - sz_top, sz_bot은 스트라이크존의 상단과 하단 (타자마다 변화)\n",
        "#    - 수평 방향: |plate_x| ≤ (홈플레이트 절반에 해당하는 폭 + 공의 반지름)\n",
        "#    - 수직 방향: sz_bot ≤ plate_z ≤ sz_top\n",
        "# -----------------------------\n",
        "\n",
        "# 공의 반지름 (inches -> feet 변환)\n",
        "BALL_RADIUS_IN = 1.43\n",
        "BALL_RADIUS_FT = BALL_RADIUS_IN / 12\n",
        "\n",
        "# 홈플레이트 절반에 해당하는 폭 (inches -> feet 변환)\n",
        "HALF_PLATE_IN = 17 / 2\n",
        "HALF_PLATE_FT = HALF_PLATE_IN / 12\n",
        "\n",
        "# 스트라이크 존 통과 여부\n",
        "in_zone = (\n",
        "    (df[\"plate_x\"].abs() <= HALF_PLATE_FT + BALL_RADIUS_FT) &\n",
        "    (df[\"plate_z\"] >= df[\"sz_bot\"] - BALL_RADIUS_FT) &\n",
        "    (df[\"plate_z\"] <= df[\"sz_top\"] + BALL_RADIUS_FT)\n",
        ")\n",
        "\n",
        "# ABS 판정 결과 생성\n",
        "df[\"abs_call\"] = np.where(in_zone, \"called_strike\", \"ball\")\n",
        "\n",
        "# 사람 심판 판정 결과 변수명 변경\n",
        "df[\"ump_call\"] = df[\"description\"]\n",
        "\n",
        "# 판정 일치 여부(판정의 정확도): 맞으면 1, 틀리면 0\n",
        "df[\"correct\"] = (df[\"abs_call\"] == df[\"ump_call\"]).astype(int)\n",
        "\n",
        "print(\"사용된 투구 수:\", len(df))\n",
        "print(\"전체 판정 정확도:\", df[\"correct\"].mean())\n",
        "\n",
        "# -----------------------------\n",
        "# 4) 스트라이크존 경계 근처 투구만 필터링\n",
        "# -----------------------------\n",
        "MARGIN_FT = 0.10  # 약 1.2인치\n",
        "\n",
        "\n",
        "# 투구의 스트라이크 존 경계까지의 거리 계산\n",
        "dx = (HALF_PLATE_FT + BALL_RADIUS_FT) - df[\"plate_x\"].abs()\n",
        "dz_low  = df[\"plate_z\"] - (df[\"sz_bot\"] - BALL_RADIUS_FT)\n",
        "dz_high = (df[\"sz_top\"] + BALL_RADIUS_FT) - df[\"plate_z\"]\n",
        "\n",
        "# 어느 하나라도 경계에서 MARGIN_FT 이내이면 borderline으로 간주\n",
        "borderline = (\n",
        "    (dx.abs() <= MARGIN_FT) |\n",
        "    (dz_low.abs() <= MARGIN_FT) |\n",
        "    (dz_high.abs() <= MARGIN_FT)\n",
        ")\n",
        "\n",
        "df = df[borderline].copy()\n",
        "\n",
        "print(\"경계 투구 수:\", len(df))\n",
        "print(\"경계 판정 정확도:\", df[\"correct\"].mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iHcFFse8aFM5",
        "outputId": "7c8a1ba3-00f5-4d9d-f0dc-49e7f5e08a97"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "This is a large query, it may take a moment to complete\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/7 [00:00<?, ?it/s]/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 14%|█▍        | 1/7 [00:03<00:23,  3.99s/it]/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 29%|██▊       | 2/7 [00:07<00:18,  3.69s/it]/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            " 43%|████▎     | 3/7 [00:09<00:11,  3.00s/it]/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "/usr/local/lib/python3.12/dist-packages/pybaseball/datahelpers/postprocessing.py:59: FutureWarning: errors='ignore' is deprecated and will raise in a future version. Use to_datetime without passing `errors` and catch exceptions explicitly instead\n",
            "  data_copy[column] = data_copy[column].apply(pd.to_datetime, errors='ignore', format=date_format)\n",
            "100%|██████████| 7/7 [00:12<00:00,  1.80s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "사용된 투구 수: 13132\n",
            "전체 판정 정확도: 0.9179865976241243\n",
            "경계 투구 수: 2789\n",
            "경계 판정 정확도: 0.7665830046611689\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "`head()`를 이용하여 추출한 데이터의 형태를 확인해보자."
      ],
      "metadata": {
        "id": "jfWhte7LgR8y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.head(5)"
      ],
      "metadata": {
        "id": "rVdGdmTDgL8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 주어진 데이터는 2024년 4월 1일부터 4월 7일까지의 MLB 경기에서 스트라이크존 경계 근처에 위치한 투구들을 모아 놓은 것이다.\n",
        "\n",
        "- 우리의 관심은, 해당 투구에 대하여 심판의 판정이 정확했는지이며, 이를 설명하는 데이터의 열은 `correct`이다. 따라서, 모의 실험에서는 `correct` 열만을 이용한다.\n",
        "\n",
        "- 이제, 주어진 데이터의 `correct` 열을 이용하여 표본과 동일한 크기의 부트스트랩 표본을 임의로 복원추출한다.\n",
        "\n",
        "- 각 부트스트랩 표본에 대해 `correct` 값의 평균을 계산하여 표본비율 $\\hat{\\theta}$를 구한다.\n",
        "\n",
        "- 이러한 부트스트랩 재표본추출과 표본비율 계산 과정을 총 2000번 반복함으로써, 표본비율 $\\hat{\\theta}$ 추정량의 분포를 데이터 기반으로 근사한다."
      ],
      "metadata": {
        "id": "nhHjSN44gY4c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 5) 부트스트랩 (Bootstrap)\n",
        "#    - 크기 n의 부트스트랩 표본을 복원추출\n",
        "#    - 각 부트스트랩 표본에서 정확도(= 표본비율) 계산\n",
        "#    - 이를 B = 2000번 반복하여 표본비율 추정량의 부트스트랩 분포 근사\n",
        "# -----------------------------\n",
        "np.random.seed(2026)\n",
        "\n",
        "B = 2000 # 부트스트랩 반복 횟수\n",
        "n = len(correct_arr) # 부트스트랩 표본 크기\n",
        "\n",
        "correct_arr = df['correct'].to_numpy()\n",
        "acc_hat = np.empty(B)\n",
        "\n",
        "# ------------------\n",
        "# 코드 채우기\n",
        "# ------------------\n",
        "\n",
        "# 부트스트랩 재표본추출\n",
        "# 부트스트랩 표본비율(정확도)\n",
        "\n",
        "\n",
        "print('[부트스트랩 결과 요약]')\n",
        "print('평균 =', acc_hat.mean())\n",
        "print('표준편차 =', acc_hat.std(ddof=1))\n",
        "print('min / max =', acc_hat.min(), acc_hat.max())"
      ],
      "metadata": {
        "id": "8fLkh7E1gueh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 이제 부트스트랩을 통해 얻은 표본비율\n",
        "$$\n",
        "\\hat{\\theta}_1^*, \\hat{\\theta}_2^*, \\dots, \\hat{\\theta}_{2000}^*\n",
        "$$\n",
        "의 히스토그램을 시각화하자.\n",
        "\n",
        "- 이를 통해, 부트스트랩 재표본추출에 의해 생성된 표본비율 추정량 $\\hat{\\theta}^*$의 분포를 파악할 수 있다."
      ],
      "metadata": {
        "id": "YwFyLvLcg-7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# -----------------------------\n",
        "# 6) 부트스트래핑 결과 시각화\n",
        "# -----------------------------\n",
        "plt.figure()\n",
        "plt.hist(acc_hat, bins=25, color='skyblue', alpha=0.5, edgecolor='white')\n",
        "plt.xlabel(\"Sample Rate\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "plt.title(f\"Empirical Distribution of Umpire Call Accuracy (n={n}, B={B})\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "2tbnM_O4g_SE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "(부트스트래핑 실습 2)\n",
        "- 이 실습에서는 전체 사용자가 매우 많은 온라인 서비스에서, 일부 사용자만을 표본으로 추출하여 알림 서비스를 활성화한 사용자의 비율을 추정하는 상황을 가정한다.\n",
        "- 모집단은 총 10,000명의 사용자로 구성되어 있으며, 이 중 30%는 알림 서비스를 활성화한 사용자이다.\n",
        "- 이제, 표본비율 $\\hat{\\theta}$에 대해 부트스트래핑으로 95% 신뢰구간을 구하고자 한다.\n",
        "- 모집단(전체 사용자 10,000명)에서 비복원추출로 크기 $n=100$의 표본을 1번 뽑고, 표본비율 $\\hat{\\theta}$를 계산한다.\n",
        "- 그 표본에 대하여, 크기 $n$의 부트스트랩을 $B=2000$번 수행하여 $\\hat{\\theta}^{*1},\\dots,\\hat{\\theta}^{*B}$를 만든다.\n",
        "- 부트스트랩 표본의 분위수(percentile)를 이용하여 95% 신뢰구간을\n",
        "  $$ \\left[\\hat{\\theta}^{*(0.025)},\\ \\hat{\\theta}^{*(0.975)}\\right] $$\n",
        "  로 계산한다."
      ],
      "metadata": {
        "id": "oAaX20k8kGaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "np.random.seed(2026)\n",
        "\n",
        "# (모집단 생성) 1: 기능 활성화 사용자, 0: 비활성 사용자\n",
        "population = np.concatenate((np.ones(3000), np.zeros(7000)), axis=0)\n",
        "\n",
        "# 크기 100의 표본 추출 후 표본비율 구하기\n",
        "n = 100\n",
        "\n",
        "# ------------------\n",
        "# 코드 채우기\n",
        "# ------------------\n",
        "\n",
        "\n",
        "\n",
        "# Bootstrap: 표본에서 복원추출로 표본비율 재계산\n",
        "B = 2000\n",
        "theta_star = np.empty(B)\n",
        "\n",
        "# ------------------\n",
        "# 코드 채우기\n",
        "# ------------------\n",
        "\n",
        "\n",
        "# 주의: 경험적 분포와 달리 sample에서 복원추출\n",
        "\n",
        "\n",
        "# 부트스트랩 신뢰구간 계산\n",
        "alpha = 0.05\n",
        "\n",
        "# ------------------\n",
        "# 코드 채우기\n",
        "# ------------------\n",
        "\n",
        "\n",
        "print(f\"95% bootstrap percentile CI = [{ci_low:.4f}, {ci_high:.4f}]\")"
      ],
      "metadata": {
        "id": "OnoywTFVleIM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "중심극한정리(CLT)를 이용한 $\\theta$의 95% 신뢰구간은 다음과 같다."
      ],
      "metadata": {
        "id": "aw6umacvnfP8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 표본비율의 표준오차\n",
        "se_clt = np.sqrt(theta_hat * (1 - theta_hat) / n)\n",
        "\n",
        "# 95% 신뢰구간의 상한과 하한 계산\n",
        "clt_ci_low = theta_hat - 1.96 * se_clt\n",
        "clt_ci_high = theta_hat + 1.96 * se_clt\n",
        "\n",
        "print(f\"95% CLT-based CI = [{clt_ci_low:.4f}, {clt_ci_high:.4f}]\")"
      ],
      "metadata": {
        "id": "0IlWhQ0XnAxL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "부트스트랩 표본의 히스토그램, 부트스트랩 표본과 중심극한정리(CLT)를 이용한 $\\theta$의 95% 신뢰구간을 시각화하면 다음과 같다."
      ],
      "metadata": {
        "id": "kSOoQMWbor60"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 시각화: bootstrap 분포 + bootstrap CI + CLT CI\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.hist(theta_star, bins=20, density=True, color=\"skyblue\",alpha=0.6, edgecolor=\"white\")\n",
        "\n",
        "plt.axvline(ci_low, linestyle=\"--\", color=\"blue\", label=\"bootstrap\")\n",
        "plt.axvline(ci_high, linestyle=\"--\", color=\"blue\")\n",
        "plt.axvline(clt_ci_low, linestyle=\"--\", color=\"salmon\", label=\"CLT\")\n",
        "plt.axvline(clt_ci_high, linestyle=\"--\", color=\"salmon\")\n",
        "plt.axvline(theta_hat, linestyle=\"-\")\n",
        "\n",
        "plt.xlabel(\"Bootstrap Sample Proportion\")\n",
        "plt.ylabel(\"Density\")\n",
        "plt.tight_layout()\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dEWtfnqioWk8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. EM Algorithm\n",
        "\n",
        "- EM 알고리즘을 적용하는 예로, 앞 장에서 다루었던 가우시안 혼합분포를 이용한 군집분석을 소개한다.\n",
        "\n",
        "- 두 개의 군집으로 이루어져 있는 데이터가 두 개의 구성원(성분 분포)을 갖는 가우시안 혼합분포를 따른다고 가정하자.\n",
        "즉,\n",
        "$$\n",
        "X_1, \\dots, X_n \\overset{i.i.d.}{\\sim} f(x \\mid \\theta)\n",
        "$$\n",
        "이며,\n",
        "$$\n",
        "f(x \\mid \\theta)\n",
        "=\n",
        "w_0 \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\n",
        "\\exp\\!\\left(-\\frac{1}{2\\sigma_0^2}(x-\\mu_0)^2\\right)\n",
        "+\n",
        "(1-w_0)\\frac{1}{\\sqrt{2\\pi\\sigma_1^2}}\n",
        "\\exp\\!\\left(-\\frac{1}{2\\sigma_1^2}(x-\\mu_1)^2\\right).\n",
        "$$\n",
        "여기서 모수는\n",
        "$\n",
        "\\theta = (\\mu_0, \\sigma_0^2, \\mu_1, \\sigma_1^2, w_0)\n",
        "$\n",
        "이다.\n",
        "\n",
        "- 로그 가능도 함수는 다음과 같다.\n",
        "$$\n",
        "\\ell(\\theta)\n",
        "=\n",
        "\\sum_{i=1}^n \\log f(X_i \\mid \\theta)\n",
        "$$\n",
        "$$\n",
        "=\n",
        "\\sum_{i=1}^n\n",
        "\\log\\!\\left(\n",
        "w_0 \\frac{1}{\\sqrt{2\\pi\\sigma_0^2}}\n",
        "\\exp\\!\\left(-\\frac{1}{2\\sigma_0^2}(X_i-\\mu_0)^2\\right)\n",
        "+\n",
        "(1-w_0)\\frac{1}{\\sqrt{2\\pi\\sigma_1^2}}\n",
        "\\exp\\!\\left(-\\frac{1}{2\\sigma_1^2}(X_i-\\mu_1)^2\\right)\n",
        "\\right).\n",
        "$$\n",
        "로그함수 내부에 복잡한 함수 형태가 포함되어 있으므로,\n",
        "로그 가능도를 최대화하는 $\\theta$를 직접 구하기는 쉽지 않다.\n",
        "\n",
        "- $i$번째 데이터 $X_i$가 어느 구성원으로부터 왔는지를 나타내는\n",
        "잠재변수 $K_i$를 도입한다.\n",
        "  - $K_i = 0$이면 $X_i \\sim N(\\mu_0, \\sigma_0^2)$\n",
        "  - $K_i = 1$이면 $X_i \\sim N(\\mu_1, \\sigma_1^2)$\n",
        "  - $K_i$는 $i$번째 데이터가 어느 군집에 속하는지 알려주는 label로 생각할 수 있다.\n",
        "  - 잠재변수 $K_i$는\n",
        "    \n",
        "    $$\n",
        "    P(K_i = 0) = w_0, \\ P(K_i = 1) = 1 - w_0\n",
        "    $$\n",
        "\n",
        "    인 확률변수이다.\n",
        "  - EM 알고리즘을 사용하면, $f(X_i \\mid \\theta)$ 대신 보다 단순한 형태의 $f(X_i, K_i \\mid \\theta)$를 이용한 최대화 문제로 바꿀 수 있다.\n",
        "\n",
        "\n",
        "- 관측자료와 잠재변수를 각각\n",
        "$$\n",
        "Y_o = X = (X_1, \\dots, X_n), \\quad\n",
        "Y_m = K = (K_1, \\dots, K_n)\n",
        "$$\n",
        "라고 하자.\n",
        "\n",
        "- 이때\n",
        "$$\n",
        "f(Y_o, Y_m \\mid \\theta)\n",
        "=\n",
        "f(X, K \\mid \\theta)\n",
        "=\n",
        "\\prod_{i=1}^n f(X_i, K_i \\mid \\theta)\n",
        "$$\n",
        "이고,\n",
        "\n",
        "$$\n",
        "\\log f(Y_o, Y_m \\mid \\theta)\n",
        "=\n",
        "\\sum_{i=1}^n \\log f(X_i, K_i \\mid \\theta)\n",
        "$$\n",
        "\n",
        "$$\n",
        "=\n",
        "-\\frac{n}{2}\\log(2\\pi)\n",
        "-\\frac{1}{2}\\sum_{i=1}^n \\log(\\sigma_{K_i}^2)\n",
        "-\\sum_{i=1}^n \\frac{(X_i-\\mu_{K_i})^2}{2\\sigma_{K_i}^2}\n",
        "+\n",
        "\\left(n-\\sum_{i=1}^n K_i\\right)\\log(w_0)\n",
        "+\n",
        "\\left(\\sum_{i=1}^n K_i\\right)\\log(1-w_0).\n",
        "$$\n",
        "\n",
        "- 가우시안 혼합분포에서 E-step을 위한 $Q$ 함수는 다음과 같다.\n",
        "\n",
        "$$\n",
        "Q(\\theta \\mid \\theta_{(r)})\n",
        "=\n",
        "\\int \\log f(Y_o, Y_m \\mid \\theta)\n",
        "\\, f(Y_m \\mid Y_o, \\theta_{(r)}) \\, dY_m\n",
        "$$\n",
        "\n",
        "$$\n",
        "=\n",
        "\\int\n",
        "\\left(\n",
        "\\sum_{i=1}^n \\log f(X_i, K_i \\mid \\theta)\n",
        "\\right)\n",
        "f(K \\mid X, \\theta_{(r)}) \\, dK\n",
        "$$\n",
        "\n",
        "$$\n",
        "=\n",
        "\\sum_{i=1}^n\n",
        "\\Big[\n",
        "\\log f(X_i, K_i=0 \\mid \\theta)\\, P(K_i=0 \\mid X_i, \\theta_{(r)})\n",
        "+\n",
        "\\log f(X_i, K_i=1 \\mid \\theta)\\, P(K_i=1 \\mid X_i, \\theta_{(r)})\n",
        "\\Big].\n",
        "$$\n",
        "\n",
        "\n",
        "- 가우시안 혼합분포에서 M-step을 위해\n",
        "$$\n",
        "\\frac{\\partial Q}{\\partial \\mu_0}=0,\\;\n",
        "\\frac{\\partial Q}{\\partial \\mu_1}=0,\\;\n",
        "\\frac{\\partial Q}{\\partial \\sigma_0^2}=0,\\;\n",
        "\\frac{\\partial Q}{\\partial \\sigma_1^2}=0,\\;\n",
        "\\frac{\\partial Q}{\\partial w_0}=0\n",
        "$$\n",
        "을 풀면 다음과 같은 업데이트 식을 얻는다.\n",
        "\n",
        "$$\n",
        "\\mu_{j(r+1)}\n",
        "=\n",
        "\\frac{\\sum_{i=1}^n X_i \\lambda_j(X_i,\\theta_{(r)})}\n",
        "{\\sum_{i=1}^n \\lambda_j(X_i,\\theta_{(r)})},\n",
        "\\quad j=0,1,\n",
        "$$\n",
        "\n",
        "$$\n",
        "\\sigma_{j(r+1)}^2\n",
        "=\n",
        "\\frac{\\sum_{i=1}^n (X_i-\\mu_{j(r+1)})^2\n",
        "\\lambda_j(X_i,\\theta_{(r)})}\n",
        "{\\sum_{i=1}^n \\lambda_j(X_i,\\theta_{(r)})},\n",
        "\\quad j=0,1,\n",
        "$$\n",
        "\n",
        "$$\n",
        "w_{0(r+1)}\n",
        "=\n",
        "\\frac{1}{n}\\sum_{i=1}^n \\lambda_0(X_i,\\theta_{(r)}).\n",
        "$$\n",
        "\n",
        "- 여기서\n",
        "$\n",
        "\\lambda_j(X_i,\\theta_{(r)})\n",
        "=\n",
        "P(K_i=j \\mid X_i,\\theta_{(r)}), \\quad j=0,1\n",
        "$\n",
        "이다.\n"
      ],
      "metadata": {
        "id": "Ztc-Zt6wsf1K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "소개된 EM 알고리즘을 함수로 작성하면 다음과 같이 나타낼 수 있다."
      ],
      "metadata": {
        "id": "7lWLRZ4CzNMl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def norm_pdf(x, mu, sigma2):\n",
        "    # N(mu, sigma2)의 확률밀도함수 값\n",
        "    return (1.0 / np.sqrt(2.0 * np.pi * sigma2)) * np.exp(-(x - mu) ** 2 / (2.0 * sigma2))\n",
        "\n",
        "def run_em_algorithm(x, mu0, sigma0_2, mu1, sigma1_2, w0, max_iter=100, tol=1e-6):\n",
        "    # 가우시안 혼합분포에 대한 EM algorithm\n",
        "    x = np.asarray(x, dtype=float)\n",
        "    n = x.size\n",
        "\n",
        "    for r in range(max_iter):\n",
        "        # lambda 정의\n",
        "\n",
        "        # ------------------\n",
        "        # 코드 채우기\n",
        "        # ------------------\n",
        "\n",
        "        # M-step\n",
        "\n",
        "        # ------------------\n",
        "        # 코드 채우기\n",
        "        # ------------------\n",
        "\n",
        "        # 수렴 판정을 위한 기준 설정\n",
        "        diff = max(\n",
        "            abs(mu0_new - mu0),\n",
        "            abs(mu1_new - mu1),\n",
        "            abs(sigma0_2_new - sigma0_2),\n",
        "            abs(sigma1_2_new - sigma1_2),\n",
        "            abs(w0_new - w0)\n",
        "        )\n",
        "\n",
        "        # 파라미터 업데이트\n",
        "        mu0, mu1 = mu0_new, mu1_new\n",
        "        sigma0_2, sigma1_2 = sigma0_2_new, sigma1_2_new\n",
        "        w0 = w0_new\n",
        "\n",
        "        # 수렴 판정\n",
        "        if diff < tol:\n",
        "            break\n",
        "\n",
        "    return {\n",
        "        \"mu0\": mu0,\n",
        "        \"sigma0_2\": sigma0_2,\n",
        "        \"mu1\": mu1,\n",
        "        \"sigma1_2\": sigma1_2,\n",
        "        \"w0\": w0\n",
        "    }"
      ],
      "metadata": {
        "id": "IxiXnbMfo-39"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "이 실습에서는 앞에서 소개한 가우시안 혼합분포 기반 EM 알고리즘을 모의실험을 통해 확인한다.\n",
        "\n",
        "- 이 예제에서는 두 개의 정규분포 구성원을 갖는 가우시안 혼합분포에서 데이터를 생성한다.\n",
        "\n",
        "- 전체 표본의 크기는\n",
        "  $\n",
        "  n = 400\n",
        "  $\n",
        "  으로 설정한다.\n",
        "\n",
        "- 혼합분포의 실제 모수는 다음과 같이 주어진다.\n",
        "  - 혼합 가중치:\n",
        "    $$\n",
        "    w_0 = 0.55\n",
        "    $$\n",
        "  - 성분 0:\n",
        "    $$\n",
        "    X \\sim N(\\mu_0, \\sigma_0^2) = N(-2.0,1.0)\n",
        "    $$\n",
        "  - 성분 1:\n",
        "    $$\n",
        "    X \\sim N(\\mu_1, \\sigma_1^2) = N(2.5,1.5)\n",
        "    $$\n",
        "\n",
        "- 각 관측치 $X_i$는 확률 $w_0$로 성분 0에서, 확률 $1-w_0$로 성분 1에서 생성되도록 한다.\n",
        "\n",
        "- 생성된 데이터 $x_1,\\dots,x_n$에 대해, 다음의 가우시안 혼합분포를 가정한다.\n",
        "  $$\n",
        "  f(x \\mid \\theta)\n",
        "  =\n",
        "  w_0 \\phi(x;\\mu_0,\\sigma_0^2)\n",
        "  +\n",
        "  (1-w_0)\\phi(x;\\mu_1,\\sigma_1^2)\n",
        "  $$\n",
        "\n",
        "- EM 알고리즘의 초기값은 다음과 같이 설정한다.\n",
        "  - $\\mu_0^{(0)} = -1.0,\\quad \\sigma_0^{2(0)} = 2.0$\n",
        "  - $\\mu_1^{(0)} = 1.0,\\quad \\sigma_1^{2(0)} = 2.0$\n",
        "  - $w_0^{(0)} = 0.5$\n",
        "\n",
        "- 위 초기값으로부터 EM 알고리즘을\n",
        "  일정 횟수 반복하여\n",
        "  $$\n",
        "  \\theta = (\\mu_0,\\sigma_0^2,\\mu_1,\\sigma_1^2,w_0)\n",
        "  $$\n",
        "  를 추정한다.\n",
        "\n",
        "- 최종적으로,\n",
        "  추정된 모수를 이용하여\n",
        "  각 성분의 정규분포 확률밀도함수와\n",
        "  혼합분포의 확률밀도함수를 함께 시각화하여\n",
        "  EM 알고리즘의 결과를 확인한다."
      ],
      "metadata": {
        "id": "3kVmaqPmzMKL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(2026)\n",
        "\n",
        "# true 값 설정\n",
        "n = 400\n",
        "true_w0 = 0.55\n",
        "true_mu0, true_sigma0_2 = -2.0, 1.0\n",
        "true_mu1, true_sigma1_2 =  2.5, 1.5\n",
        "\n",
        "# 관측치 뽑기\n",
        "k = (np.random.rand(n) < true_w0).astype(int)  # # 각 관측치가 어떤 성분 분포에서 왔는지 결정(boolean으로 나오므로 k = 1이면 성분 0에서 추출되도록 만들기 위해 반전해서 사용)\n",
        "x = np.empty(n)\n",
        "x[k == 1] = np.random.normal(loc=true_mu0, scale=np.sqrt(true_sigma0_2), size=(k == 1).sum())\n",
        "x[k == 0] = np.random.normal(loc=true_mu1, scale=np.sqrt(true_sigma1_2), size=(k == 0).sum())\n",
        "\n",
        "# --- 이제 데이터만 주어졌다고 가정합시다...! 우리는 true 값을 몰라서, w0, mu0, mu1, sigma0_2, sigma1_2를 추정할거예요...! ---\n",
        "\n",
        "# 초기값 설정(반복 알고리즘은 초기값 설정 필요!)\n",
        "init_mu0, init_sigma0_2 = -1.0, 2.0\n",
        "init_mu1, init_sigma1_2 = 1.0, 2.0\n",
        "init_w0 = 0.5\n",
        "\n",
        "# 위에서 정의한 EM 알고리즘 함수를 이용해서 모수 추정\n",
        "est = run_em_algorithm(\n",
        "    x,\n",
        "    mu0=init_mu0, sigma0_2=init_sigma0_2,\n",
        "    mu1=init_mu1, sigma1_2=init_sigma1_2,\n",
        "    w0=init_w0\n",
        ")\n",
        "\n",
        "print(est)"
      ],
      "metadata": {
        "id": "FDbaco2Jtb1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# EM algorithm 실행 결과 저장\n",
        "mu0_hat = est[\"mu0\"]\n",
        "mu1_hat = est[\"mu1\"]\n",
        "sigma0_2_hat = est[\"sigma0_2\"]\n",
        "sigma1_2_hat = est[\"sigma1_2\"]\n",
        "w0_hat = est[\"w0\"]\n",
        "\n",
        "# x축 grid 생성\n",
        "x_grid = np.linspace(x.min() - 1.0, x.max() + 1.0, 800)\n",
        "\n",
        "# 혼합분포 각 성분의 PDF\n",
        "pdf0 = norm_pdf(x_grid, mu0_hat, sigma0_2_hat)\n",
        "pdf1 = norm_pdf(x_grid, mu1_hat, sigma1_2_hat)\n",
        "\n",
        "# 혼합분포 PDF\n",
        "mixture_pdf = w0_hat * pdf0 + (1.0 - w0_hat) * pdf1\n",
        "\n",
        "# 시각화\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# 전체 데이터 히스토그램\n",
        "plt.hist(x, bins=50, density=True,\n",
        "         alpha=0.5, color=\"skyblue\", edgecolor=\"white\",\n",
        "         label=\"Observed data\")\n",
        "\n",
        "# 각 성분의 정규분포 PDF\n",
        "plt.plot(\n",
        "    x_grid, pdf0,\n",
        "    color=\"blue\",\n",
        "    label=r\"Component 0: $N(\\mu_0, \\sigma_0^2)$\"\n",
        ")\n",
        "\n",
        "plt.plot(\n",
        "    x_grid, pdf1,\n",
        "    color=\"salmon\",\n",
        "    label=r\"Component 1: $N(\\mu_1, \\sigma_1^2)$\"\n",
        ")\n",
        "\n",
        "# 혼합분포 PDF\n",
        "plt.plot(\n",
        "    x_grid, mixture_pdf,\n",
        "    color=\"black\", linestyle=\"--\",\n",
        "    label=\"Mixture PDF\"\n",
        ")\n",
        "\n",
        "plt.title(\"Gaussian Mixture Model fitted by EM algorithm\")\n",
        "plt.xlabel(\"value\")\n",
        "plt.ylabel(\"density\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y4OVmlKJuTWb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}